{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/albanda/CE888-2023/blob/main/lab7-CNN/cnn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4JgSMREZ4-4K",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "# CE888 Lab 7\n",
        "Dr Ana Matran-Fernandez,  University of Essex.\n",
        "\n",
        "## Training a CNN Classifier\n",
        "\n",
        "- Lab Objective: Create, train, and test a CNN model\n",
        "\n",
        "### Instructions:\n",
        "\n",
        "1. Go through each code block,\n",
        " study and make sure you understand each of them,\n",
        " and fill in the missing \"TODO\" parts.\n",
        "\n",
        "2. Save a neural network for the MNIST dataset and run it as an attachment through the Moodle CE888 Lab 7 quiz.\n",
        "\n",
        "3. Save a neural network for the Cifar10 dataset and run it as an attachment through the Moodle CE888 Lab 7 quiz.\n",
        "\n",
        "4. If you have time, work through the \"checklist of things to do\" in the final block of this page.\n",
        "\n",
        "Before you start (if you're running this locally; this is not necessary on Colab):\n",
        "- Check you have the python packages numpy, matplotlib, tensorflow.\n",
        "- e.g., install them with \"pip3 install numpy, matplotlib, tensorflow\"\n",
        "- IMPORTANT!!!!! If you're doing the lab on Colab, make sure you've changed your runtime to GPU. This will significantly reduce the training time of the networks (this should take seconds if you're on GPU).\n",
        "\n",
        "Acknowledgements:\n",
        "- This lab session is based on Dr Michael Fairbank's CE811 materials."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y-xvFG6_4-4N",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "# Imports\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.__version__"
      ],
      "metadata": {
        "id": "hPzgG_aQGk0O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ylTmVzUh4-4N",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "## Load a vision benchmark dataset\n",
        "\n",
        "- We will start with the MNIST hand-written numeric digits dataset.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_name = \"mnist\"\n",
        "\n",
        "if dataset_name == \"cifar10\":\n",
        "    dataset = tf.keras.datasets.cifar10\n",
        "    class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer','dog', 'frog', 'horse', 'ship', 'truck']\n",
        "    # CIFAR10 images are 32*32*3.\n",
        "    accuracy_threshold = 0.6  # Moodle progress checker expects >60% accuracy on CIFAR10\n",
        "elif dataset_name == \"fashion\":\n",
        "    dataset = tf.keras.datasets.fashion_mnist\n",
        "    class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat','Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
        "    accuracy_threshold = 0.8\n",
        "elif dataset_name == \"mnist\":\n",
        "    accuracy_threshold = 0.96  # Moodle progress checker expects >96% accuracy on MNIST.\n",
        "    dataset = tf.keras.datasets.mnist\n",
        "    class_names = ['zero', 'one', 'two', 'three', 'four','five', 'six', 'seven', 'eight', 'nine']\n",
        "else:\n",
        "    print(\"unknown dataset\")\n",
        "    raise Exception(\"Please specify a valid dataset!\")\n",
        "\n",
        "(train_images0, train_labels0), (test_images0, test_labels0) = dataset.load_data()\n",
        "\n",
        "print('Train: X=%s, y=%s' % (train_images0.shape, train_labels0.shape))\n",
        "print('Test: X=%s, y=%s' % (test_images0.shape, test_labels0.shape))\n",
        "\n",
        "train_labels = train_labels0.reshape(-1)\n",
        "test_labels = test_labels0.reshape(-1)\n"
      ],
      "metadata": {
        "id": "Yj9hKJ05Xu4Q",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y7SotazN4-4R",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "## Visualise the Dataset\n",
        "\n",
        "- Show a few pictures of the images we are trying to learn from..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ulLbA8bg4-4R",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "# plot a few images\n",
        "plt.figure(figsize=(10,10))\n",
        "for i in range(25):\n",
        "    # define subplot\n",
        "    plt.subplot(5,5,i+1)\n",
        "    # plot raw pixel data\n",
        "    plt.imshow(train_images0[i], cmap=plt.get_cmap('gray'))\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    plt.grid(False)\n",
        "    if class_names != None:\n",
        "        # Add a label underneath, if we have one...\n",
        "        plt.xlabel(class_names[train_labels[i]])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i2KC-fZ54-4S",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "## Prep the data\n",
        "- The keras datasets contain integer pixel intensities from 0 to 255.  We must rescale this to floats from 0 to 1."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tX30Od2s4-4S",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "# Rescale greyscale from 8 bit to floating point (by dividing by 255)\n",
        "test_images = (test_images0 / 255.0).astype(np.float32) # 10000 test patterns, shape 10000*28*28\n",
        "train_images = (train_images0 / 255.0).astype(np.float32) # 60000 train patterns, shape 60000*28*28\n",
        "\n",
        "if len(train_images.shape) == 3:  # images must be rank-4 tensors [number_of_images, dimension1, dimension2, number_of_channels]\n",
        "    # add a single channel to these black-and-white images\n",
        "    train_images=train_images.reshape(list(train_images.shape)+[1])\n",
        "    test_images=test_images.reshape(list(test_images.shape)+[1])\n",
        "    print(\"Reshaped images from \", train_images0.shape, \"to\", train_images.shape, \"so that 'channel' dimension exists\")\n",
        "\n",
        "num_classification_categories = train_labels.max() + 1\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0R8LH5JU4-4T",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "## Define a model\n",
        "- We'll bulid our neural network here.\n",
        "- TO DO: Modify the simple model defined below\n",
        " so that it has the following structure.\n",
        "- Use relu activation functions everywhere,\n",
        " except for the last layer which must have a softmax activation function.\n",
        "- Use kernel size (3, 3) for each convolutional layer\n",
        " and pool size (2, 2) for each max-pooling layer.\n",
        "- Ensure you obtain the architecture exactly as shown here...\n",
        "\n",
        "```\n",
        "_________________________________________________________________\n",
        "Layer (type)                 Output Shape              Param #\n",
        "=================================================================\n",
        "layer1 (Conv2D)              (None, 28, 28, 6)         60\n",
        "_________________________________________________________________\n",
        "layer2 (MaxPooling2D)        (None, 14, 14, 6)         0\n",
        "_________________________________________________________________\n",
        "layer3 (Conv2D)              (None, 14, 14, 3)         165\n",
        "_________________________________________________________________\n",
        "layer4 (MaxPooling2D)        (None, 7, 7, 3)           0\n",
        "_________________________________________________________________\n",
        "layer5 (Flatten)             (None, 147)               0\n",
        "_________________________________________________________________\n",
        "layer6 (Dense)               (None, 128)               18944\n",
        "_________________________________________________________________\n",
        "layer7 (Dense)               (None, 10)                1290\n",
        "=================================================================\n",
        "Total params: 20,459\n",
        "Trainable params: 20,459\n",
        "Non-trainable params: 0\n",
        "_________________________________________________________________\n",
        "\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EQgSH3ms4-4V",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "# build model with CNN architecture\n",
        "model = keras.Sequential()\n",
        "\n",
        "# YOUR CODE HERE (do NOT specify the input shape in the first layer)\n",
        "\n",
        "model.add(layers.Dense(128, activation='relu'))\n",
        "model.add(layers.Dense(num_classification_categories, activation='softmax'))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xcAVsuHs4-4Y",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "## View Model Summary\n",
        "\n",
        "- Have a look at the model summary here and compare with the output above to make sure they're the same."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tpLbsbfA4-4Y",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "model.build(input_shape=(None,) + train_images.shape[1:])\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6cTbrfZQ4-4Z",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "if model.count_params() > 800000 and dataset_name == \"cifar10\":\n",
        "    print(\"The lab7 quiz has a 10MB limit on your model size, so use a smaller model if you want to validate through the auto-marker!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0BRsLapj4-4a",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "## Train the network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SRmkQch14-4a",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "optimizer = keras.optimizers.Adam()\n",
        "\n",
        "model.compile(optimizer=optimizer,\n",
        "              loss=keras.losses.SparseCategoricalCrossentropy(),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(train_images, train_labels,\n",
        "                batch_size=128,\n",
        "                epochs=5,\n",
        "                validation_data=(test_images, test_labels))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tbMRFr2I4-4b",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "## Plot graphs of learning progress...\n",
        "\n",
        "- Have a look at these graphs, and try to work out whether any\n",
        " overfitting has occurred, or whether we would gain any benefit\n",
        " from training for more or fewer epochs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GUZAkMwM4-4b",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "plt.plot(history.history['accuracy'], label='train_accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label = 'val_accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend(loc='lower right')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PXV1snCb4-4b",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "## Inspect how well the system is working...\n",
        "- The test set has a lot of images in it,\n",
        " but we can only view 25 at a time.\n",
        "- You can rerun the next code block several times,\n",
        " to get a different random set of samples from the test set.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "KyVRpZ__4-4b",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10,11))\n",
        "# plot 25 random images from the test set.\n",
        "first_index = np.random.randint(len(test_images)-25)\n",
        "for i in range(first_index,first_index+25):\n",
        "    # define subplot\n",
        "    plt.subplot(5,5,i+1-first_index)\n",
        "    # plot raw pixel data\n",
        "    plt.imshow(test_images0[i], cmap=plt.get_cmap('gray'))\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    plt.grid(False)\n",
        "    if class_names != None:\n",
        "        # Add a label underneath, if we have one...\n",
        "        prediction = model(test_images[i:i+1])[0,:]\n",
        "        prediction_class = np.argmax(prediction)\n",
        "        true_label = test_labels[i]\n",
        "        class_name = class_names[prediction_class]\n",
        "        plt.xlabel(class_name+\" \"+(\"CORRECT\" if prediction_class==true_label else \"WRONG\\n{}\".format(class_names[true_label])))\n",
        "plt.subplots_adjust(hspace=0.2)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qCzjHGdB4-4d",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "## Save the model\n",
        "- Once you have the correct layers created (as described above)\n",
        " and have trained a model which can score >96% on the\n",
        " MNIST digits validation set, save your model with the next code block.\n",
        "- Then use your saved model as an attachment to pass questions 1+2 of\n",
        " the Lab 7 Quiz on Moodle."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vvLSvopJ4-4d",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "if history.history[\"val_accuracy\"][-1] > accuracy_threshold:\n",
        "    print(\"Your model is accurate enough!\")\n",
        "    # Save the model into a local folder\n",
        "    model.save('Model1'+dataset_name+'.keras')\n",
        "else:\n",
        "    print(\"Accuracy is below the threshold!\")\n",
        "    raise Exception(\"Your model isn't accurate enough to pass the progress checker!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YxudD1sn4-4d",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "# CIFAR10 image set\n",
        "\n",
        "- Repeat all of the steps above, but change the dataset_name in the\n",
        " top code-block to \"cifar10\"\n",
        "- We need a bigger network for CIFAR10 than we did for MNIST.\n",
        " Use this architecture:\n",
        "\n",
        "```\n",
        "_________________________________________________________________\n",
        "Layer (type)                 Output Shape              Param #\n",
        "=================================================================\n",
        "layer1 (Conv2D)              (None, 32, 32, 16)        448\n",
        "_________________________________________________________________\n",
        "layer2 (Conv2D)              (None, 32, 32, 32)        4640\n",
        "_________________________________________________________________\n",
        "layer3 (MaxPooling2D)        (None, 16, 16, 32)        0\n",
        "_________________________________________________________________\n",
        "layer4 (Dropout)             (None, 16, 16, 32)        0\n",
        "_________________________________________________________________\n",
        "layer5 (Conv2D)              (None, 16, 16, 64)        18496\n",
        "_________________________________________________________________\n",
        "layer6 (Conv2D)              (None, 16, 16, 64)        36928\n",
        "_________________________________________________________________\n",
        "layer7 (MaxPooling2D)        (None, 8, 8, 64)          0\n",
        "_________________________________________________________________\n",
        "layer8 (Dropout)             (None, 8, 8, 64)          0\n",
        "_________________________________________________________________\n",
        "layer9 (Flatten)             (None, 4096)              0\n",
        "_________________________________________________________________\n",
        "layer10 (Dense)              (None, 128)               524416\n",
        "_________________________________________________________________\n",
        "layer11 (Dense)              (None, 10)                1290\n",
        "=================================================================\n",
        "Total params: 586,218\n",
        "Trainable params: 586,218\n",
        "Non-trainable params: 0\n",
        "_________________________________________________________________\n",
        "```\n",
        "\n",
        "- For the dropout layers, use a Dropout rate of 0.2\n",
        "- Train for at least 5 epochs,\n",
        " and you should be able to score >60% on the test set for CIFAR10.\n",
        "- Note that the above architecture is still pretty small\n",
        " (particularly, by only having 64 filters).\n",
        " But we need this particular smaller architecture,\n",
        " so that the auto-marker can handle it comfortably.\n",
        "\n",
        "Once you have this working, upload your saved model to questions 3+4 of the progress checker."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MwYeipp74-4d",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "## Checklist of further things to do\n",
        "\n",
        "Okay you should have completed the progress checker by now.\n",
        "But if you want to explore further, then...\n",
        "\n",
        "1. Check you have made 2 different convolutional neural network classifiers, one for MNIST and one for Cifar10.\n",
        "\n",
        "2. Check that in each case you have inspected the results,\n",
        " the validation accuracy and decided whether more or fewer epochs\n",
        " would be beneficial.\n",
        "\n",
        "3. If you have time remaining then see if you can improve performance\n",
        " on Cifar10.\n",
        "    * Possible methods:\n",
        "        * Try training for longer.\n",
        "        * Add more convolutional layers.\n",
        "        * Add more filters at each convolutional layer.\n",
        "    * Have a look at the CNN structure used here (https://machinelearningmastery.com/how-to-develop-a-cnn-from-scratch-for-cifar-10-photo-classification/) to see how you could score >80% on CIFAR10 (see the final architecture at the bottom of the page). However, this requires a lot of CPU/GPU time.\n",
        "\n",
        "4. If time permits, then see what the effect of changing the RELU activation functions to tanh.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GpUjxA7taKiM",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}